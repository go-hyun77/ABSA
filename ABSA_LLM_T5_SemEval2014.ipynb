{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1A_m9uWnTdShb5XC3nhaST1LmfR8kSTb8",
      "authorship_tag": "ABX9TyMbmwdlJV5w02v22qYclbl3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/go-hyun77/ABSA/blob/f1-scoring-optimize/ABSA_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aspect-Based Sentiment Analysis (ABSA) with T5\n",
        "# --------------------------------------------------\n",
        "# This notebook shows how to fine-tune a T5 model for ABSA using HuggingFace.\n",
        "# SemEval2014 dataset (aspect + sentiment annotations).\n",
        "\n",
        "!pip install transformers datasets sentencepiece -q\n",
        "!pip install datasets==3.6.0\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "L5d8yE95AOwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb8cade-6e0d-41b7-ac3c-0e0fca444adb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets==3.6.0 in /usr/local/lib/python3.12/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.17.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "dataset = load_dataset(\"alexcadillon/SemEval2014Task4\", \"restaurants\")"
      ],
      "metadata": {
        "id": "8BlHGImlhFNu"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine dataset\n",
        "train_data = dataset[\"train\"]\n",
        "\n",
        "# print first 10 entries of train split\n",
        "for i in range(10):\n",
        "    print(f\"{i+1}: {train_data[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8_IQMpuJsjh",
        "outputId": "f23401c9-3406-49e6-9243-e7ba324e4103"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: {'sentenceId': '3121', 'text': 'But the staff was so horrible to us.', 'aspectTerms': [{'term': 'staff', 'polarity': 'negative', 'from': '8', 'to': '13'}], 'aspectCategories': [{'category': 'service', 'polarity': 'negative'}]}\n",
            "2: {'sentenceId': '2777', 'text': \"To be completely fair, the only redeeming factor was the food, which was above average, but couldn't make up for all the other deficiencies of Teodora.\", 'aspectTerms': [{'term': 'food', 'polarity': 'positive', 'from': '57', 'to': '61'}], 'aspectCategories': [{'category': 'food', 'polarity': 'positive'}, {'category': 'anecdotes/miscellaneous', 'polarity': 'negative'}]}\n",
            "3: {'sentenceId': '1634', 'text': \"The food is uniformly exceptional, with a very capable kitchen which will proudly whip up whatever you feel like eating, whether it's on the menu or not.\", 'aspectTerms': [{'term': 'food', 'polarity': 'positive', 'from': '4', 'to': '8'}, {'term': 'kitchen', 'polarity': 'positive', 'from': '55', 'to': '62'}, {'term': 'menu', 'polarity': 'neutral', 'from': '141', 'to': '145'}], 'aspectCategories': [{'category': 'food', 'polarity': 'positive'}]}\n",
            "4: {'sentenceId': '2534', 'text': 'Where Gabriela personaly greets you and recommends you what to eat.', 'aspectTerms': [], 'aspectCategories': [{'category': 'service', 'polarity': 'positive'}]}\n",
            "5: {'sentenceId': '583', 'text': \"For those that go once and don't enjoy it, all I can say is that they just don't get it.\", 'aspectTerms': [], 'aspectCategories': [{'category': 'anecdotes/miscellaneous', 'polarity': 'positive'}]}\n",
            "6: {'sentenceId': '2846', 'text': \"Not only was the food outstanding, but the little 'perks' were great.\", 'aspectTerms': [{'term': 'food', 'polarity': 'positive', 'from': '17', 'to': '21'}, {'term': 'perks', 'polarity': 'positive', 'from': '51', 'to': '56'}], 'aspectCategories': [{'category': 'food', 'polarity': 'positive'}, {'category': 'service', 'polarity': 'positive'}]}\n",
            "7: {'sentenceId': '1571', 'text': 'It is very overpriced and not very tasty.', 'aspectTerms': [], 'aspectCategories': [{'category': 'food', 'polarity': 'negative'}, {'category': 'price', 'polarity': 'negative'}]}\n",
            "8: {'sentenceId': '1458', 'text': 'Our agreed favorite is the orrechiete with sausage and chicken (usually the waiters are kind enough to split the dish in half so you get to sample both meats).', 'aspectTerms': [{'term': 'orrechiete with sausage and chicken', 'polarity': 'positive', 'from': '27', 'to': '62'}, {'term': 'waiters', 'polarity': 'positive', 'from': '76', 'to': '83'}, {'term': 'meats', 'polarity': 'neutral', 'from': '152', 'to': '157'}, {'term': 'dish', 'polarity': 'neutral', 'from': '113', 'to': '117'}], 'aspectCategories': [{'category': 'food', 'polarity': 'positive'}, {'category': 'service', 'polarity': 'positive'}]}\n",
            "9: {'sentenceId': '3161', 'text': 'The Bagels have an outstanding taste with a terrific texture, both chewy yet not gummy.', 'aspectTerms': [{'term': 'Bagels', 'polarity': 'positive', 'from': '4', 'to': '10'}], 'aspectCategories': [{'category': 'food', 'polarity': 'positive'}]}\n",
            "10: {'sentenceId': '2391', 'text': 'Nevertheless the food itself is pretty good.', 'aspectTerms': [{'term': 'food', 'polarity': 'positive', 'from': '17', 'to': '21'}], 'aspectCategories': [{'category': 'food', 'polarity': 'positive'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten dataset\n",
        "indexes = [train_data[i] for i in range(20)]  # first 20 entries\n",
        "\n",
        "\n",
        "rows = []\n",
        "for i in indexes:\n",
        "    sentence_id = i[\"sentenceId\"]\n",
        "    text = i[\"text\"]\n",
        "\n",
        "    # If aspect terms exist, iterate through them\n",
        "    if i[\"aspectTerms\"]:\n",
        "        for asp in i[\"aspectTerms\"]:\n",
        "            rows.append({\n",
        "                \"sentenceId\": sentence_id,\n",
        "                \"text\": text,\n",
        "                \"aspect_term\": asp[\"term\"],\n",
        "                \"term_polarity\": asp[\"polarity\"],\n",
        "                \"category\": None,  # Add these to maintain consistent columns\n",
        "                \"category_polarity\": None # Add these to maintain consistent columns\n",
        "            })\n",
        "    # If no explicit aspect terms, still record categories\n",
        "    if i[\"aspectCategories\"]:\n",
        "        for cat in i[\"aspectCategories\"]:\n",
        "            rows.append({\n",
        "                \"sentenceId\": sentence_id,\n",
        "                \"text\": text,\n",
        "                \"aspect_term\": None, # Add these to maintain consistent columns\n",
        "                \"term_polarity\": None, # Add these to maintain consistent columns\n",
        "                \"category\": cat[\"category\"],\n",
        "                \"category_polarity\": cat[\"polarity\"]\n",
        "            })\n",
        "\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(rows)\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a3uLdYKqBcy",
        "outputId": "2a058154-8343-4f69-efc8-8706222372fc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sentenceId                                               text aspect_term  \\\n",
            "0       3121               But the staff was so horrible to us.       staff   \n",
            "1       3121               But the staff was so horrible to us.        None   \n",
            "2       2777  To be completely fair, the only redeeming fact...        food   \n",
            "3       2777  To be completely fair, the only redeeming fact...        None   \n",
            "4       2777  To be completely fair, the only redeeming fact...        None   \n",
            "5       1634  The food is uniformly exceptional, with a very...        food   \n",
            "6       1634  The food is uniformly exceptional, with a very...     kitchen   \n",
            "7       1634  The food is uniformly exceptional, with a very...        menu   \n",
            "8       1634  The food is uniformly exceptional, with a very...        None   \n",
            "9       2534  Where Gabriela personaly greets you and recomm...        None   \n",
            "\n",
            "  term_polarity                 category category_polarity  \n",
            "0      negative                     None              None  \n",
            "1          None                  service          negative  \n",
            "2      positive                     None              None  \n",
            "3          None                     food          positive  \n",
            "4          None  anecdotes/miscellaneous          negative  \n",
            "5      positive                     None              None  \n",
            "6      positive                     None              None  \n",
            "7       neutral                     None              None  \n",
            "8          None                     food          positive  \n",
            "9          None                  service          positive  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define model\n",
        "\n",
        "model_name = \"t5-small\" #try \"google/flan-t5-base\" for better results\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "RChew2YNg34W"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create aspect-sentiment pairs from dataset\n",
        "import json\n",
        "\n",
        "def format_target(ex):\n",
        "    \"\"\"\n",
        "    Build a T5-safe target string like:\n",
        "      \"aspect=food, sentiment=positive; aspect=service, sentiment=negative\"\n",
        "    or \"none\" if no aspects.\n",
        "    \"\"\"\n",
        "    pairs = []\n",
        "    for asp in ex.get(\"aspectTerms\", []):\n",
        "        term = asp.get(\"term\")\n",
        "        pol = asp.get(\"polarity\")\n",
        "        if term is None or pol is None:\n",
        "            continue\n",
        "        # normalize\n",
        "        pairs.append(f\"aspect={term.strip()}, sentiment={pol.strip().lower()}\")\n",
        "    return \"; \".join(pairs) if pairs else \"none\"\n",
        "\n"
      ],
      "metadata": {
        "id": "lodARW4LCsfc"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to tokenize inputs (as in the plain sentences + aspect terms/values) for model to train on\n",
        "\n",
        "def preprocess(ex):\n",
        "    instruction = (\n",
        "        \"Extract aspect-based sentiment. \"\n",
        "        \"Return outputs in the exact format: \"\n",
        "        \"'aspect=<term>, sentiment=<positive|negative|neutral>' \"\n",
        "        \"separated by '; ' for multiple aspects. If no aspects, return 'none'.\\n\\n\"\n",
        "    )\n",
        "\n",
        "    # INCLUDE instruction in the input\n",
        "    input_text = instruction + \"ABSA: \" + ex[\"text\"]\n",
        "\n",
        "    target_text = format_target(ex)\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        input_text,\n",
        "        text_target=target_text,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    # Add raw text and aspectTerms to the processed example for evaluation\n",
        "    model_inputs[\"raw_text\"] = ex[\"text\"]\n",
        "    model_inputs[\"raw_aspects\"] = ex.get(\"aspectTerms\", [])\n",
        "\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "p8b5teV4753k"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply preprocess function to each entry in training and validation test splits\n",
        "train_dataset = dataset[\"train\"].map(preprocess, remove_columns=[])\n",
        "valid_dataset = dataset[\"test\"].map(preprocess, remove_columns=[])"
      ],
      "metadata": {
        "id": "RMj1wkxv8GAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set PyTorch format (so Trainer can use them directly)\n",
        "train_dataset.set_format(type=\"torch\")\n",
        "valid_dataset.set_format(type=\"torch\")"
      ],
      "metadata": {
        "id": "-di-PG1c3sNu"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quick verify format_target on one raw example\n",
        "print(\"RAW example:\", dataset[\"train\"][0])               #loaded HF dataset\n",
        "print(\"FORMATTED target:\", format_target(dataset[\"train\"][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqGNIucy3ReA",
        "outputId": "d4e36f50-564b-401e-e73c-8a71a497b585"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAW example: {'sentenceId': '3121', 'text': 'But the staff was so horrible to us.', 'aspectTerms': [{'term': 'staff', 'polarity': 'negative', 'from': '8', 'to': '13'}], 'aspectCategories': [{'category': 'service', 'polarity': 'negative'}]}\n",
            "FORMATTED target: aspect=staff, sentiment=negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick decode check (ensure tokenizer didn't strip or change the target)\n",
        "print(\"Decoded input (train[0]):\")\n",
        "print(tokenizer.decode(train_dataset[0][\"input_ids\"], skip_special_tokens=True))\n",
        "print(\"Decoded target (train[0]):\")\n",
        "print(tokenizer.decode(train_dataset[0][\"labels\"], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwE9q7r03xWi",
        "outputId": "edddfb7f-09ea-443c-e924-cd0edb765566"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded input (train[0]):\n",
            "Extract aspect-based sentiment. Return outputs in the exact format: 'aspect=term>, sentiment=positive|negative|neutral>' separated by ';'for multiple aspects. If no aspects, return 'none'. ABSA: But the staff was so horrible to us.\n",
            "Decoded target (train[0]):\n",
            "aspect=staff, sentiment=negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sanity check, labels of first index of training data set\n",
        "print(tokenizer.decode(train_dataset[0][\"labels\"], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM2FeoYK9eIX",
        "outputId": "6081db59-2278-4e3e-ef9f-1195afd53cbd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aspect=staff, sentiment=negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sanity check, input of training data post-preprocessing\n",
        "print(tokenizer.decode(train_dataset[0][\"input_ids\"], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJuiWrOB0vjq",
        "outputId": "091c2d5f-1761-4f39-9638-18bbf7d4975c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extract aspect-based sentiment. Return outputs in the exact format: 'aspect=term>, sentiment=positive|negative|neutral>' separated by ';'for multiple aspects. If no aspects, return 'none'. ABSA: But the staff was so horrible to us.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sanity check, raw format_target output\n",
        "print(format_target(dataset[\"train\"][0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Smskknnj1GVX",
        "outputId": "ac9ee7a6-3f7c-4cc4-85f0-902e09313a49"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aspect=staff, sentiment=negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load model\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "X-DNhMzq8lpt"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training setup and parameters\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./absa_t5\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=6,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=50,\n",
        "    fp16=False,    # set True if your GPU supports it\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "  model=model,\n",
        "  args=args,\n",
        "  train_dataset=train_dataset,\n",
        "  eval_dataset=valid_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "IOKfZll08uRB"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train model, no need to execute this block if loading saved model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "2tQVDzKFFTIV",
        "outputId": "1b0bd0b7-5902-437b-a081-2f7327cf59d6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2286' max='2286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2286/2286 6:56:58, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.163200</td>\n",
              "      <td>0.086505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.076500</td>\n",
              "      <td>0.058833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.069300</td>\n",
              "      <td>0.051112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.071300</td>\n",
              "      <td>0.048222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.054600</td>\n",
              "      <td>0.046494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.056700</td>\n",
              "      <td>0.045654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2286, training_loss=0.3016708865044728, metrics={'train_runtime': 25072.7909, 'train_samples_per_second': 0.728, 'train_steps_per_second': 0.091, 'total_flos': 617361627414528.0, 'train_loss': 0.3016708865044728, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount drive folder for saving trained model\n",
        "#!fusermount -u /content/drive\n",
        "#!rm -rf /content/drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "model_dir = \"/content/drive/MyDrive/ABSA_T5_Model\"\n",
        "!ls /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "F4NfMCNTDYuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5e7a5a-9137-4848-ce64-6736bf6f5eaa"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'3rd Iteration Document'  'CPSC 301'\t  'CPSC 439'  'CPSC 566'\n",
            " ABSA_T5_Model\t\t  'CPSC 311'\t  'CPSC 440'  'CPSC 585'\n",
            "'AP GOV'\t\t  'CPSC 315'\t  'CPSC 452'  'CPSC 589'\n",
            " BIO101\t\t\t  'CPSC 323'\t  'CPSC 471'  'EGCP 401'\n",
            " Books\t\t\t  'CPSC 332'\t  'CPSC 481'  'EVO Food Places.xlsx'\n",
            "'Colab Notebooks'\t  'CPSC 335'\t  'CPSC 485'   MATH338\n",
            "'CPSC 121'\t\t  'CPSC 351'\t  'CPSC 531'   Misc.\n",
            "'CPSC 223J'\t\t  'CPSC 353 458'  'CPSC 544'  'Oct Genesis.png'\n",
            "'CPSC 240'\t\t  'CPSC 362'\t  'CPSC 548'  'PSC Biotech'\n",
            "'CPSC 254'\t\t  'CPSC 375'\t  'CPSC 552'  'Test Folder'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "model.save_pretrained(model_dir)\n",
        "tokenizer.save_pretrained(model_dir)\n"
      ],
      "metadata": {
        "id": "k__5iOxntBSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07278b44-a2e2-4638-e0a3-012679edbcfd"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/ABSA_T5_Model/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/ABSA_T5_Model/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/ABSA_T5_Model/spiece.model',\n",
              " '/content/drive/MyDrive/ABSA_T5_Model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer and model from your Drive\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_dir, local_files_only=True)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_dir, local_files_only=True)\n",
        "\n",
        "\n",
        "print(\"Model path:\", model.config._name_or_path)\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in model.parameters()) // 1e6, \"M\")"
      ],
      "metadata": {
        "id": "I-aYS7FLAcub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c694b763-8898-46cb-a129-0eba866cd1c4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model path: /content/drive/MyDrive/ABSA_T5_Model\n",
            "Number of parameters: 60.0 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test model with text input\n",
        "\n",
        "# 1️⃣ Confirm model path\n",
        "print(\"Model path:\", model.config._name_or_path)\n",
        "\n",
        "# 2️⃣ Confirm the prefix was used during training\n",
        "print(\"Example training input:\", dataset[\"train\"][0][\"text\"])\n",
        "\n",
        "# 3️⃣ Try inference without prefix (if you didn't train with one)\n",
        "def absa_predict(text):\n",
        "    instruction = (\n",
        "        \"Extract aspect-based sentiment. \"\n",
        "        \"Return outputs in the exact format: \"\n",
        "        \"'aspect=<term>, sentiment=<positive|negative|neutral>' \"\n",
        "        \"separated by '; ' for multiple aspects. If no aspects, return 'none'.\\n\\n\"\n",
        "    )\n",
        "    full_input = instruction + \"ABSA: \" + text\n",
        "\n",
        "    inputs = tokenizer(full_input, return_tensors=\"pt\", padding=True)\n",
        "    outputs = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=128,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "#pass sample text input to test absa\n",
        "print(absa_predict(\"The food was amazing but the service was terrible.\"))\n"
      ],
      "metadata": {
        "id": "vbnjIu1xcAH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0644f0b6-8067-4549-e5d4-f7b360fe8441"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model path: /content/drive/MyDrive/ABSA_T5_Model\n",
            "Example training input: But the staff was so horrible to us.\n",
            "aspect=food, sentiment=positive; aspect=service, sentiment=positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decoded training label:\", tokenizer.decode(train_dataset[0][\"labels\"], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs_Se2sWGy6n",
        "outputId": "821cda82-3818-49b1-ab5d-22a5420e781b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded training label: aspect=staff, sentiment=negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decoded training input:\", tokenizer.decode(train_dataset[0][\"input_ids\"], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW4QLLyIHCbG",
        "outputId": "c8ab8b8f-2997-4ac8-ac90-bd3d099bd80c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded training input: Extract aspect-based sentiment. Return outputs in the exact format: 'aspect=term>, sentiment=positive|negative|neutral>' separated by ';'for multiple aspects. If no aspects, return 'none'. ABSA: But the staff was so horrible to us.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "#parse absa text outputs into structured data\n",
        "\n",
        "# load the saved model (if in a new session)!!!\n",
        "# tokenizer = T5Tokenizer.from_pretrained(\"/content/drive/MyDrive/ABSA_T5_Model\")\n",
        "# model = T5ForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/ABSA_T5_Model\")\n",
        "\n",
        "def absa_generate(text, max_length=128):\n",
        "    instruction = (\n",
        "        \"Extract aspect-based sentiment. \"\n",
        "        \"Return outputs in format: 'aspect=<term>, sentiment=<positive|negative|neutral>' \"\n",
        "        \"separated by '; ' or 'none' if no aspects.\\n\\n\"\n",
        "    )\n",
        "    input_text = instruction + \"ABSA: \" + text\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
        "    outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=max_length, num_beams=4, early_stopping=True)\n",
        "    raw = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return raw\n",
        "\n",
        "def parse_aspect_string(s):\n",
        "    \"\"\"\n",
        "    Parse outputs like:\n",
        "      'aspect=food, sentiment=positive; aspect=service, sentiment=negative'\n",
        "    into list of dicts [{\"aspect\":\"food\",\"sentiment\":\"positive\"}, ...]\n",
        "    Returns [] if s indicates 'none' or empty output.\n",
        "    \"\"\"\n",
        "    s = s.strip()\n",
        "    if not s or s.lower() in {\"none\", \"no aspects\", \"[]\"}:\n",
        "        return []\n",
        "    pairs = []\n",
        "    # split on ';' then parse each part\n",
        "    for part in s.split(\";\"):\n",
        "        part = part.strip()\n",
        "        if not part:\n",
        "            continue\n",
        "        # match aspect=<term>, sentiment=<polarity>\n",
        "        m = re.search(r\"aspect\\s*=\\s*(.+?)\\s*,\\s*sentiment\\s*=\\s*(positive|negative|neutral)\", part, flags=re.I)\n",
        "        if m:\n",
        "            aspect = m.group(1).strip()\n",
        "            sentiment = m.group(2).strip().lower()\n",
        "            pairs.append({\"aspect\": aspect, \"sentiment\": sentiment})\n",
        "        else:\n",
        "            # fallback: try `X was Y` style (rare) or ignore\n",
        "            m2 = re.search(r\"(.+?)\\s+was\\s+(positive|negative|neutral)\", part, flags=re.I)\n",
        "            if m2:\n",
        "                pairs.append({\"aspect\": m2.group(1).strip(), \"sentiment\": m2.group(2).lower()})\n",
        "    return pairs"
      ],
      "metadata": {
        "id": "duyKF5kwZ_eO"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#correct pairs\n",
        "def extract_good_pairs(example):\n",
        "    \"\"\"\n",
        "    Convert dataset example with `aspectTerms` into our tuple list form\n",
        "    \"\"\"\n",
        "    pairs = []\n",
        "    for asp in example.get(\"aspectTerms\", []):\n",
        "        term = asp.get(\"term\")\n",
        "        pol = asp.get(\"polarity\")\n",
        "        if term and pol:\n",
        "            pairs.append({\"aspect\": term, \"sentiment\": pol.lower()})\n",
        "    return pairs"
      ],
      "metadata": {
        "id": "mFCoPz7q5Zd3"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output test\n",
        "for s in [\n",
        "    \"The food was amazing but the service was terrible.\",\n",
        "    \"I like the ambiance, but the drinks are overpriced.\"\n",
        "]:\n",
        "    raw = absa_generate(s)\n",
        "    print(\"RAW:\", raw)\n",
        "    print(\"PARSED:\", parse_aspect_string(raw))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPa2rBu95GvP",
        "outputId": "f06cf673-26fe-47fa-8ad6-8a105c02d186"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAW: aspect=food, sentiment=positive; aspect=service, sentiment=positive\n",
            "PARSED: [{'aspect': 'food', 'sentiment': 'positive'}, {'aspect': 'service', 'sentiment': 'positive'}]\n",
            "\n",
            "RAW: aspect=ambiance, sentiment=positive; aspect=drinks, sentiment=positive\n",
            "PARSED: [{'aspect': 'ambiance', 'sentiment': 'positive'}, {'aspect': 'drinks', 'sentiment': 'positive'}]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#f1 score compute function\n",
        "\n",
        "def compute_f1(true_pairs, pred_pairs):\n",
        "    \"\"\"\n",
        "    true_pairs: list of dicts [{\"aspect\":..., \"sentiment\":...}, ...]\n",
        "    pred_pairs: list of dicts of same form\n",
        "    returns precision, recall, f1 for the joint match (aspect+sentiment)\n",
        "    \"\"\"\n",
        "    true_set = set((p[\"aspect\"].lower(), p[\"sentiment\"].lower()) for p in true_pairs)\n",
        "    pred_set = set((p[\"aspect\"].lower(), p[\"sentiment\"].lower()) for p in pred_pairs)\n",
        "\n",
        "    TP = len(true_set & pred_set)\n",
        "    FP = len(pred_set - true_set)\n",
        "    FN = len(true_set - pred_set)\n",
        "\n",
        "    precision = TP / (TP + FP + 1e-12)\n",
        "    recall = TP / (TP + FN + 1e-12)\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-12) if (precision + recall) > 0 else 0.0\n",
        "    return precision, recall, f1"
      ],
      "metadata": {
        "id": "REUF3q60aNCI"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_on_dataset(split_dataset, limit=None):\n",
        "    tot_p = tot_r = tot_f1 = 0.0\n",
        "    n = 0\n",
        "\n",
        "    for i, ex in enumerate(tqdm(split_dataset)):\n",
        "        if limit and i >= limit:\n",
        "            break\n",
        "\n",
        "        # 1. Get the good labels from preprocess metadata\n",
        "        gold = extract_good_pairs({\n",
        "            \"aspectTerms\": ex[\"raw_aspects\"]\n",
        "        })\n",
        "\n",
        "        # 2. Build the input text\n",
        "        input_text = \"ABSA: \" + ex[\"raw_text\"]\n",
        "\n",
        "        # 3. Run model inference\n",
        "        raw_output = absa_generate(input_text)\n",
        "\n",
        "        # 4. Parse prediction into same structure as good pairs\n",
        "        pred = parse_aspect_string(raw_output)\n",
        "\n",
        "        # 5. Compute F1 for this sample\n",
        "        p, r, f1 = compute_f1(gold, pred)\n",
        "\n",
        "        tot_p += p\n",
        "        tot_r += r\n",
        "        tot_f1 += f1\n",
        "        n += 1\n",
        "\n",
        "    return {\n",
        "        \"precision\": tot_p / n,\n",
        "        \"recall\": tot_r / n,\n",
        "        \"f1\": tot_f1 / n\n",
        "    }"
      ],
      "metadata": {
        "id": "Va8t2dNRaSCd"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = evaluate_on_dataset(valid_dataset, limit=200)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmDfMMqSacPS",
        "outputId": "1c29a3de-6e6d-421b-c80c-3b02082cf8e5"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 200/800 [03:06<09:19,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'precision': 0.4370833333330023, 'recall': 0.40116666666637685, 'f1': 0.41323809523755906}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    t = dataset[\"test\"][i][\"text\"]\n",
        "    print(\"INPUT:\", t)\n",
        "    print(\"MODEL OUTPUT:\", absa_predict(t))\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr7X85ntwK_J",
        "outputId": "886e8522-69f5-4c35-eee3-e83c543fab1b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT: The bread is top notch as well.\n",
            "MODEL OUTPUT: aspect=bread, sentiment=positive\n",
            "--------------------------------------------------\n",
            "INPUT: I have to say they have one of the fastest delivery times in the city.\n",
            "MODEL OUTPUT: aspect=delivery times, sentiment=positive\n",
            "--------------------------------------------------\n",
            "INPUT: Food is always fresh and hot- ready to eat!\n",
            "MODEL OUTPUT: aspect=Food, sentiment=positive\n",
            "--------------------------------------------------\n",
            "INPUT: Did I mention that the coffee is OUTSTANDING?\n",
            "MODEL OUTPUT: aspect=caffee, sentiment=positive\n",
            "--------------------------------------------------\n",
            "INPUT: Certainly not the best sushi in New York, however, it is always fresh, and the place is very clean, sterile.\n",
            "MODEL OUTPUT: aspect=sushi, sentiment=positive; aspect=place, sentiment=positive\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}
